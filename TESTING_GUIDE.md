# ğŸ§ª Testing Guide - Advanced Analytics

## Quick Test Checklist

Use this guide to verify that all advanced analytics features are working correctly.

## âœ… Pre-Testing Setup

### 1. Install Dependencies
```bash
python setup_analytics.py
# or manually:
pip install -e .
```

### 2. Start Application
```bash
python admin_portal.py
```

### 3. Login
```
Username: admin
Password: admin123
```

### 4. Ensure Sample Data Exists
You need at least 10-20 feedback entries with varied data:
- Different areas/locations
- Different categories
- Different timestamps (spread over days/weeks)
- Different sentiments
- Different urgency levels
- Different statuses

## ğŸ§ª Test Suite

### TEST 1: Navigation & UI
**Objective:** Verify basic navigation works

**Steps:**
1. âœ“ Login to Admin Portal
2. âœ“ Click "Analytics" in sidebar
3. âœ“ See three radio options: Advanced, Standard, Data Tables
4. âœ“ Select "ğŸš€ Advanced Analytics"
5. âœ“ Verify 5 tabs appear: Trend Analysis, SLA Monitoring, Geospatial Heatmap, Department Performance, Time Patterns

**Expected Result:** All UI elements load without errors

**Status:** â˜ Pass â˜ Fail

---

### TEST 2: Trend Analysis Tab
**Objective:** Test trend visualization and forecasting

**Steps:**
1. âœ“ Click "ğŸ“Š Trend Analysis" tab
2. âœ“ Change period selector: daily â†’ weekly â†’ monthly
3. âœ“ Verify trend chart updates
4. âœ“ Check forecast section shows 4 periods
5. âœ“ Verify sentiment trends chart appears
6. âœ“ Check category trends chart appears
7. âœ“ Read trend summary text

**Expected Results:**
- Charts render without errors
- Different periods show different aggregations
- Forecast values are reasonable
- Summary text is informative

**Status:** â˜ Pass â˜ Fail

**Notes:**
```
Chart displayed: Yes / No
Forecast shown: Yes / No
Summary accurate: Yes / No
```

---

### TEST 3: SLA Monitoring Tab
**Objective:** Test SLA prediction and monitoring

**Steps:**
1. âœ“ Click "âš ï¸ SLA Monitoring" tab
2. âœ“ Check three metric cards:
   - Breached SLAs
   - At Risk
   - SLA Compliance %
3. âœ“ Verify recommendations appear
4. âœ“ Check breached tickets section
5. âœ“ Check at-risk tickets section
6. âœ“ Verify probability percentages are shown
7. âœ“ Verify recommended actions are displayed

**Expected Results:**
- Metrics calculate correctly
- Tickets are categorized properly
- Probability scores are between 0-100%
- Recommendations are actionable

**Status:** â˜ Pass â˜ Fail

**Notes:**
```
Breached count: ___
At-risk count: ___
Compliance %: ___
Probabilities reasonable: Yes / No
```

---

### TEST 4: Geospatial Heatmap Tab
**Objective:** Test map visualizations

**Steps:**
1. âœ“ Click "ğŸ—ºï¸ Geospatial Heatmap" tab
2. âœ“ Select "Heatmap" map type
3. âœ“ Verify map loads with markers/density
4. âœ“ Select "Hotspots" map type
5. âœ“ Verify top hotspots appear
6. âœ“ Check hotspot cards below map
7. âœ“ Select "Category Distribution" map type
8. âœ“ Choose a category from dropdown
9. âœ“ Verify map updates
10. âœ“ Check recommendations section

**Expected Results:**
- All three map types render
- Maps are interactive (pan/zoom)
- Hotspot cards show scores
- Category filtering works
- Tooltips appear on hover

**Status:** â˜ Pass â˜ Fail

**Notes:**
```
Heatmap loaded: Yes / No
Hotspots visible: Yes / No
Category filter works: Yes / No
Map interactive: Yes / No
```

---

### TEST 5: Department Performance Tab
**Objective:** Test department analytics

**Steps:**
1. âœ“ Click "ğŸ¢ Department Performance" tab
2. âœ“ Check overall performance score card
3. âœ“ Verify top performer card
4. âœ“ Verify bottom performer card (if >1 dept)
5. âœ“ Check horizontal bar chart comparison
6. âœ“ Expand each department details
7. âœ“ Verify 4 metrics shown per department:
   - Total Tickets
   - Resolution Rate
   - Satisfaction
   - SLA Compliance
8. âœ“ Check recommendations section

**Expected Results:**
- Overall score calculated correctly (0-100)
- Top/bottom performers identified
- Comparison chart shows all departments
- Individual metrics are accurate
- Expandable sections work

**Status:** â˜ Pass â˜ Fail

**Notes:**
```
Overall score: ___/100
Top performer: ___________
Department count: ___
All metrics visible: Yes / No
```

---

### TEST 6: Time Patterns Tab
**Objective:** Test temporal analysis

**Steps:**
1. âœ“ Click "â° Time Patterns" tab
2. âœ“ Verify day/hour heatmap appears
3. âœ“ Check heatmap has 7 rows (days)
4. âœ“ Check heatmap has 24 columns (hours)
5. âœ“ Verify color intensity varies
6. âœ“ Check hourly distribution bar chart
7. âœ“ Hover over cells to see tooltips

**Expected Results:**
- Heatmap renders correctly
- Days ordered Monday-Sunday
- Hours ordered 0-23
- Color scale represents complaint count
- Bar chart shows hourly totals
- Tooltips show day, hour, and count

**Status:** â˜ Pass â˜ Fail

**Notes:**
```
Heatmap displayed: Yes / No
Days visible: ___
Hours visible: ___
Bar chart shown: Yes / No
```

---

### TEST 7: Standard Analytics View
**Objective:** Test backward compatibility

**Steps:**
1. âœ“ Return to Analytics page
2. âœ“ Select "ğŸ“Š Standard Analytics" radio button
3. âœ“ Verify standard charts appear:
   - Sentiment donut chart
   - Category bar chart
   - Urgency bar chart
   - Status pie chart
   - Timeline chart
   - Category vs Sentiment heatmap
4. âœ“ Check response metrics at bottom

**Expected Results:**
- All standard charts still work
- No errors or broken visualizations
- Metrics calculate correctly

**Status:** â˜ Pass â˜ Fail

---

### TEST 8: Data Tables View
**Objective:** Test tabular data display

**Steps:**
1. âœ“ Select "ğŸ“‹ Data Tables" radio button
2. âœ“ Check three statistics tables:
   - By Category
   - By Urgency
   - By Status
3. âœ“ Verify location statistics table (if area data exists)

**Expected Results:**
- All tables display data
- Counts are accurate
- Tables are sortable/readable

**Status:** â˜ Pass â˜ Fail

---

### TEST 9: Performance Test
**Objective:** Test with larger datasets

**Steps:**
1. âœ“ Use dataset with 50+ entries
2. âœ“ Navigate through all tabs
3. âœ“ Measure page load times
4. âœ“ Check for any lag or freezing
5. âœ“ Verify charts render smoothly

**Expected Results:**
- All tabs load in < 5 seconds
- No UI freezing
- Charts render without delay
- Interactions remain smooth

**Status:** â˜ Pass â˜ Fail

**Performance Notes:**
```
Tab load time: ___ seconds
Chart render time: ___ seconds
Smooth interactions: Yes / No
```

---

### TEST 10: Error Handling
**Objective:** Test with edge cases

**Steps:**
1. âœ“ Test with empty dataset (no feedback)
2. âœ“ Test with minimal data (1-2 entries)
3. âœ“ Test with missing fields (no area, no category)
4. âœ“ Test with all tickets resolved (no open SLA)
5. âœ“ Verify appropriate messages appear

**Expected Results:**
- Empty data shows "No data available" message
- Missing fields show "Insufficient data" message
- App doesn't crash
- Helpful error messages displayed

**Status:** â˜ Pass â˜ Fail

**Error Messages:**
```
Empty data handled: Yes / No
Missing fields handled: Yes / No
Appropriate messages: Yes / No
```

---

## ğŸ“Š Test Results Summary

Fill in after completing all tests:

| Test # | Feature | Status | Notes |
|--------|---------|--------|-------|
| 1 | Navigation & UI | â˜ Pass â˜ Fail | |
| 2 | Trend Analysis | â˜ Pass â˜ Fail | |
| 3 | SLA Monitoring | â˜ Pass â˜ Fail | |
| 4 | Geospatial Heatmap | â˜ Pass â˜ Fail | |
| 5 | Department Performance | â˜ Pass â˜ Fail | |
| 6 | Time Patterns | â˜ Pass â˜ Fail | |
| 7 | Standard Analytics | â˜ Pass â˜ Fail | |
| 8 | Data Tables | â˜ Pass â˜ Fail | |
| 9 | Performance | â˜ Pass â˜ Fail | |
| 10 | Error Handling | â˜ Pass â˜ Fail | |

**Overall Pass Rate:** ___/10 (___%)

---

## ğŸ› Common Issues & Solutions

### Issue: Map not loading
**Solution:** 
- Check internet connection (maps need external resources)
- Verify Plotly is installed: `pip install plotly`
- Clear browser cache

### Issue: No data in charts
**Solution:**
- Ensure feedback data exists
- Check required fields are populated (timestamp, category, status)
- Verify database connection

### Issue: SLA predictions showing 0%
**Solution:**
- Ensure tickets have status = 'New', 'In Review', or 'In Progress'
- Check urgency field is populated
- Verify timestamp field exists

### Issue: Department performance not showing
**Solution:**
- Ensure category field is populated
- Check department mapping in `src/advanced_analytics.py`
- Add your categories to mapping

### Issue: Heatmap shows no locations
**Solution:**
- Ensure area field is populated in feedback
- Add area coordinates in `src/geospatial_viz.py`
- Or add latitude/longitude to feedback entries

### Issue: Charts render slowly
**Solution:**
- Reduce dataset size (filter by date range)
- Close other browser tabs
- Check system resources

---

## ğŸ”§ Manual Testing Commands

### Test Advanced Analytics Module
```python
from src.advanced_analytics import AdvancedAnalytics
from src.data_manager import DataManager

# Initialize
dm = DataManager()
analytics = AdvancedAnalytics()

# Get data
df = dm.get_feedback_dataframe()

# Test each function
trends = analytics.calculate_trends(df, period='weekly')
print("Trends:", trends['summary'])

sla = analytics.predict_sla_breaches(df)
print("SLA Breaches:", sla['breach_count'])

geo = analytics.analyze_geospatial_distribution(df)
print("Hotspots:", len(geo['location_hotspots']))

dept = analytics.analyze_department_performance(df)
print("Departments:", len(dept['department_metrics']))
```

### Test Geospatial Module
```python
from src.geospatial_viz import GeospatialVisualizer
from src.data_manager import DataManager

# Initialize
dm = DataManager()
geo_viz = GeospatialVisualizer()

# Get data
df = dm.get_feedback_dataframe()

# Test maps
heatmap = geo_viz.create_complaint_heatmap(df)
hotspot_map = geo_viz.create_hotspot_map(df)
temporal = geo_viz.create_temporal_heatmap(df)

print("Maps created successfully!")
```

---

## ğŸ“ Test Report Template

```
ADVANCED ANALYTICS TEST REPORT
==============================

Date: _______________
Tester: _______________
Version: 2.0

ENVIRONMENT:
- Python Version: _______________
- OS: _______________
- Browser: _______________
- Database: PostgreSQL

DATASET:
- Total Feedback Entries: ___
- Date Range: ___ to ___
- Categories: ___
- Areas: ___

TEST RESULTS:
[Paste summary table here]

ISSUES FOUND:
1. _______________
2. _______________
3. _______________

RECOMMENDATIONS:
1. _______________
2. _______________
3. _______________

OVERALL STATUS: â˜ PASS â˜ FAIL â˜ PARTIAL

SIGN-OFF:
Tested by: _______________
Date: _______________
```

---

## ğŸ¯ Acceptance Criteria

The advanced analytics implementation passes if:

- âœ… All 5 analytics tabs load without errors
- âœ… At least 8/10 tests pass
- âœ… No critical bugs or crashes
- âœ… Charts render within 5 seconds
- âœ… Data accuracy verified
- âœ… Error handling works properly
- âœ… Documentation is complete

---

## ğŸ“ Support

If tests fail:
1. Check ADVANCED_ANALYTICS.md for troubleshooting
2. Review QUICK_START_ANALYTICS.md for setup
3. Inspect browser console for errors
4. Check Streamlit terminal output for errors
5. Verify database connection and data

---

**Good luck testing! ğŸš€**
